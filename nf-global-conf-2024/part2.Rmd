---
title: "Analysis Workshop"
author: "NF-OSI Staff"
date: "2024-06-22"
output:
  ioslides_presentation:
    widescreen: true
---

```{r setup-pkgs, include=FALSE}
library(ggplot2)
library(grid)
library(gridExtra)
library(png)
```

# Part II

## This Workshop Section

- Quick contextual overview (10 min)
- cBioPortal (20 min)
- Code examples (30 min)
- Questions, discussions, technical support (20 min)

<div class="notes"> 

Hi, this is the second part of the workshop. 
We have showcased some CTF data and analysis and, in this part, we are going to complement that with something more focused on NTAP data.

</div>

## Contextual Overview

<div class="notes"> 
If some of you attended a previous webinar we did called "NF Data Exploration Made Easy", you might recognize this. 
This workshop is a continuation of that theme, to facilitate data exploration by showing you different tools as well as a bit of training to encourage more flexible explorations. 
So here is the context and the tie-in.
</div>

```{r tools-spectrum-funs, include=FALSE}
read_logo <- function(filename) {
  img <- readPNG(filename)
  rasterGrob(img, interpolate = TRUE)
}

logos <- list(
  aws = list(file = "resources/aws_logo.png", x = 0.1, y = 0.8),
  azure = list(file = "resources/azure_logo.png", x = 0.1, y = 0.6),
  gcp = list(file = "resources/gcp_logo.png", x = 0.1, y = 0.4),
  palantir = list(file = "resources/palantir_logo.png", x = 0.3, y = 0.5),
  cavatica = list(file = "resources/cavatica_logo.png", x = 0.5, y = 0.6),
  cbioportal = list(file = "resources/cbioportal_logo.png", x = 0.75, y = 0.8),
  codeocean = list(file = "resources/codeocean_logo.png", x = 0.5, y = 0.38),
  pharmacodb = list(file = "resources/pharmacodb_logo.png", x = 0.9, y = 0.65),
  plutobio = list(file = "resources/plutobio_logo.png", x = 0.7, y = 0.5),
  colab = list(file = "resources/colab_logo.png", x = 0.5, y = 0.8) 
)
```

```{r tools-spectrum, out.width="100%", echo=FALSE, cache=FALSE}
gradient_df <- data.frame(
  x = seq(0, 1, length.out = 100),
  y = rep(1, 100),
  fill = seq(0, 1, length.out = 100)
)[-c(1,100), ]

p <- ggplot() +
  theme_void() + # Remove axes and background
  xlim(0, 1) + ylim(0, 1) + # Set x and y limits
  geom_tile(data = gradient_df, aes(x = x, y = 0.95, fill = fill), height = 0.03) +
  scale_fill_gradient(low = "navy", high = "red", guide="none") +
  annotate("text", x = c(0.1, 0.3, 0.5, 0.7, 0.9), y = 0.9, label = c("1", "2", "3", "4", "5"), size = 6) + # Add labels
  annotate("text", x = 0.1, y = 1, label = "Flexible (but complex)", size = 4, hjust = 0) + # Add labels
  annotate("text", x = 0.9, y = 1, label = "Usable (very specific tasks)", size = 4, hjust = 1)

scale_factor <- 0.24

# Add logos to the plot with increased size
for (logo in logos) {
  p <- p + annotation_custom(read_logo(logo$file), 
                             xmin = logo$x - scale_factor / 2, 
                             xmax = logo$x + scale_factor / 2, 
                             ymin = logo$y - scale_factor / 2, 
                             ymax = logo$y + scale_factor / 2)
}

p
```

## Analysis Environments

<div class="notes"> 
This is a more detailed landscape comparison of the previous slide.
What we've added is how well these platforms connect to the data on Synapse, and what it might cost you (time/effort/money) to get data to this environment and work in it. 
**Reiterate: we're not being prescriptive, just trying to inform about where things at are currently**.
Synapse very open to different compute solutions, and we're working on more, it's just that things move slowly because take a lot of engineering effort.
But ultimately, more options = more chances of success for different types of researchers.  
Why we're showing different solutions today!
</div>

## Previous Analysis in Cavatica

<div class="notes">
So in the previous session, you did analysis in Cavatica.
</div>

```{r here-cavatica, out.width="100%", echo=FALSE}

p + geom_rect(aes(
  xmin = logos$cavatica$x - 0.15, xmax = logos$cavatica$x + 0.15, 
  ymin = logos$cavatica$y - 0.05, ymax = logos$cavatica$y + 0.05), 
  color = "red", fill = NA, linewidth = 1)


```

## Now: Exploratory Analysis in cBioPortal

```{r here-at-cbioportal, out.width="100%", echo=FALSE}

p + geom_rect(aes(
  xmin = logos$cbioportal$x - 0.1, xmax = logos$cbioportal$x + 0.1, 
  ymin = logos$cbioportal$y - 0.05, ymax = logos$cbioportal$y + 0.05), 
  color = "red", fill = NA, linewidth = 1)
```


<div class="notes">
First, we are going to use some data that is already visualized outside the NF Data Portal (in cBioPortal). This is the NTAP-funded JHU data in cBioPortal. We’ll show you what you can do in cBioportal.

1. Basic clinical summary of cohort (male vs female) cancer types – Synapse can be used for similar simple cohort visualization tools per dataset but you would have to configure it yourself.
2. Quickly check individuals/samples with a specific mutation in Gene X (Mutated Genes panel).
3. Get quick stats on nonsynonymous tumor mutational burden (TMB) – the total number of nonsynonymous mutations per coding area of a tumor genome is a biomarker and sometimes useful for immunotherapy.
4. Download clinical data through the UI.
5. Download the processed cBioPortal dataset by following the Synapse link.
</div>

<div class="notes"> 
**SWITCH FROM SLIDE PRESENTATION HERE TO GO TO CBIOPORTAL.**
</div>

## Debrief cBioPortal

- Data was "pre-loaded" for analysis
- Good for exploratory analysis
- Not guaranteed to be most up-to-date
- Can't do certain things

<div class="notes">
You saw just now that cBioPortal is good for quick overview and certain types of exploratory analysis. 
But there are situations when you might want to explore the original raw data or just do more with the processed data than you can in the current app. 

While we have some processed data outside the NF Data Portal, there are the usual benefits and limitations: 
it can give you some insights without much work but if you want to reuse the data to do more original and *flexible* analyses, you should be motivated to go Synapse and get this data. 

Now we're going to move to a different part of the spectrum to a more flexible analysis environment. 
</div>


## Now: Analysis in X

```{r here-x, out.width="100%", echo=FALSE}

# Not sure whether X will be Colab or Codeocean, use Colab unless we get access to Codeocean
new_pos <- logos$colab

p + geom_rect(aes(
  xmin = new_pos$x - 0.1, xmax = new_pos$x + 0.1, 
  ymin = new_pos$y - 0.08, ymax = new_pos$y + 0.08), 
  color = "red", fill = NA, linewidth = 1)


```

<div class="notes"> 
**EXIT SLIDE PRESENTATION HERE TO GO TO X**
</div>


## Debrief X

- Understand raw data and metadata organization in Synapse
- Learned simple steps of how to connect/load the data into a particular analysis environment
- Learned basics of how to use this particular analysis environment and its features
- Learned basics of collaborative and reproducible science

## Summary of Analysis Approaches Covered

<div class="notes"> 
We were able to cover a lot of different analysis environments and tools in this workshop!
Analysis environment: Cavatica, cBioPortal, <Google Colab or Code Ocean>
Packages: synapseclient, <name of Bioconductor package in other part>, TumorDecon
Languages: R and Python
</div>

```{r, out.width="100%", echo=FALSE}
summary_p <- ggplot() +
  theme_void() +
  xlim(0, 1) + ylim(0, 1)

scale2 <- 1.5

for (logo in logos[c("cavatica", "cbioportal", "colab")]) {
  summary_p <- summary_p + 
    annotation_custom(
      read_logo(logo$file),  
      xmin = logo$x - scale_factor / scale2,
      xmax = logo$x + scale_factor / scale2,
      ymin = logo$y - scale_factor / scale2, 
      ymax = logo$y + scale_factor / scale2)
}

# Add language logos
summary_p <- summary_p +
   annotation_custom(read_logo("resources/r_logo.png"), xmin = 0.15, xmax = 0.3, ymin = 0.5,  ymax = 0.7) +
   annotation_custom(read_logo("resources/python_logo.png"), xmin = 0.6, xmax = 0.9, ymin = 0.4,  ymax = 0.7)

# TODO: Add package names?

summary_p

```

<div class="notes">
Final motivating thought: sharing data reflects optimism about human ingenuity for
advancing computational methods to process, integrate data in more effective ways to unlock new insights.   
</div>